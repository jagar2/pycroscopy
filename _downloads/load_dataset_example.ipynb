{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Load Dataset\n\n\nConventionally, the h5py package is used to create, read, write, and modify h5 files.\n\nPycroscopy uses h5py to read hdf5 files and the ioHDF5 subpackage (a light wrapper around h5py) within pycroscopy\nto create / write back to the file. Please see the example on writing hdf5 files for more information on creating and\nwriting to h5 files using pycroscopy.\n\nIn the event that modification / addition of data to the existing file is of interest,\nit is recommended that the file be opened using ioHDF5. The same h5py handles can be obtained easily from ioHDF5.\nNote that ioHDF5 always reads the files in the 'r+' mode that allows modification of the file.\n\nIn this example, we will be loading the Raw_Data dataset from the hdf5 file.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Code source: pycroscopy\n# Liscense: MIT\n\nfrom __future__ import division, print_function, absolute_import, unicode_literals\nimport h5py\ntry:\n    # This package is not part of anaconda and may need to be installed.\n    import wget\nexcept ImportError:\n    import pip\n    pip.main(['install', 'wget'])\n    import wget\n\nfrom os import remove\nimport pycroscopy as px\n\n# Downloading the file from the pycroscopy Github project\nurl = 'https://raw.githubusercontent.com/pycroscopy/pycroscopy/master/data/BELine_0004.h5'\nh5_path = 'temp.h5'\n_ = wget.download(url, h5_path)\n\n# h5_path = px.io_utils.uiGetFile(caption='Select .h5 file', filter='HDF5 file (*.h5)')\n\n# Read the file using using h5py:\nh5_file1 = h5py.File(h5_path, 'r')\n\n# Look at the contents of the file:\npx.hdf_utils.print_tree(h5_file1)\n\n# Access the \"Raw_Data\" dataset from its absolute path\nh5_raw1 = h5_file1['Measurement_000/Channel_000/Raw_Data']\nprint('h5_raw1: ', h5_raw1)\n\n# We can get to the same dataset through relative paths:\n\n# Access the Measurement_000 group first\nh5_meas_grp = h5_file1['Measurement_000']\nprint('h5_meas_grp:', h5_meas_grp)\n\n# Now we can access the \"Channel_000\" group via the h5_meas_grp object\nh5_chan_grp = h5_meas_grp['Channel_000']\n\n# And finally, the same raw dataset can be accessed as:\nh5_raw1_alias_1 = h5_chan_grp['Raw_Data']\nprint('h5_raw1_alias_1:', h5_raw1_alias_1)\n\n# Another way to get this dataset is via functions written in pycroscopy:\nh5_dsets = px.hdf_utils.getDataSet(h5_file1, 'Raw_Data')\nprint('h5_dsets:', h5_dsets)\n\n# In this case, there is only a single Raw_Data, so we an access it simply as:\nh5_raw1_alias_2 = h5_dsets[0]\nprint('h5_raw1_alias_2:', h5_raw1_alias_2)\n\n# Let's just check to see if these are indeed aliases of the same dataset:\nprint('All aliases of the same dataset?', h5_raw1 == h5_raw1_alias_1 and h5_raw1 == h5_raw1_alias_2)\n\n# Let's close this file\nh5_file1.close()\n\n# Load the dataset with pycroscopy\nhdf = px.ioHDF5(h5_path)\n\n# Getting the same h5py handle to the file:\nh5_file2 = hdf.file\n\nh5_raw2 = h5_file2['Measurement_000/Channel_000/Raw_Data']\nprint('h5_raw2:', h5_raw2)\n\nh5_file2.close()\n\n# Delete the temporarily downloaded h5 file:\nremove(h5_path)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}