{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Spectral Unmixing\n\n\nS. Somnath\\ :sup:`1,2`,  R. K. Vasudevan\\ :sup:`1,3`\n* :sup:`1` Institute for Functional Imaging of Materials\n* :sup:`2` Advanced Data and Workflows Group\n* :sup:`3` Center for Nanophase Materials Sciences\n\nOak Ridge National Laboratory, Oak Ridge TN 37831, USA\n\nIn this notebook we load some spectral data, and perform basic data analysis, including:\n========================================================================================\n* KMeans Clustering\n* Non-negative Matrix Factorization\n* Principal Component Analysis\n* NFINDR\n\nSoftware Prerequisites:\n=======================\n* Standard distribution of **Anaconda** (includes numpy, scipy, matplotlib and sci-kit learn)\n* **pysptools** (will automatically be installed in the next step)\n* **cvxopt** for fully constrained least squares fitting\n    * install in a terminal via **`conda install -c https://conda.anaconda.org/omnia cvxopt`**\n* **pycroscopy** : Though pycroscopy is mainly used here for plotting purposes only, it's true capabilities\nare realized through the ability to seamlessly perform these analyses on any imaging dataset (regardless\nof origin, size, complexity) and storing the results back into the same dataset among other things\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "#Import packages\n\n# Ensure that this code works on both python 2 and python 3\nfrom __future__ import division, print_function, absolute_import, unicode_literals\n\n# basic numeric computation:\nimport numpy as np\n\n# The package used for creating and manipulating HDF5 files:\nimport h5py\n\n# Plotting and visualization:\nimport matplotlib.pyplot as plt\nfrom mpl_toolkits.axes_grid1 import make_axes_locatable\n\n# for downloading files:\nimport wget\nimport os\n\n# multivariate analysis:\nfrom sklearn.cluster import KMeans\nfrom sklearn.decomposition import NMF\nfrom pysptools import eea\nimport pysptools.abundance_maps as amp\nfrom pysptools.eea import nfindr\n\n# finally import pycroscopy:\nimport pycroscopy as px\n\n\"\"\"\n  \n\"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The Data\n========\n\nIn this example, we will work on a **Band Excitation Piezoresponse Force Microscopy (BE-PFM)** imaging dataset\nacquired from advanced atomic force microscopes. In this dataset, a spectra was colllected for each position in a two\n dimensional grid of spatial locations. Thus, this is a three dimensional dataset that has been flattened to a two\ndimensional matrix in accordance with the pycroscopy data format.\n\nFortunately, all statistical analysis, machine learning, spectral unmixing algorithms, etc. only accept data that is\nformatted in the same manner of [position x spectra] in a two dimensional matrix.\n\nWe will begin by downloading the BE-PFM dataset from Github\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "data_file_path = 'temp_um.h5'\n# download the data file from Github:\nurl = 'https://raw.githubusercontent.com/pycroscopy/pycroscopy/master/data/BELine_0004.h5'\n_ = wget.download(url, data_file_path, bar=None)\n\nhdf = px.ioHDF5(data_file_path)\nh5_file = hdf.file\n\nprint('Contents of data file:')\nprint('----------------------')\npx.hdf_utils.print_tree(h5_file)\nprint('----------------------')\n\nh5_meas_grp = h5_file['Measurement_000']\n\n# Extracting some basic parameters:\nnum_rows = px.hdf_utils.get_attr(h5_meas_grp,'grid_num_rows')\nnum_cols = px.hdf_utils.get_attr(h5_meas_grp,'grid_num_cols')\n\n# Getting a reference to the main dataset:\nh5_main = h5_meas_grp['Channel_000/Raw_Data']\n\n# Extracting the X axis - vector of frequencies\nh5_spec_vals = px.hdf_utils.getAuxData(h5_main,'Spectroscopic_Values')[-1]\nfreq_vec = np.squeeze(h5_spec_vals.value) * 1E-3\n\nprint('Data currently of shape:', h5_main.shape)\n\nx_label = 'Frequency (kHz)'\ny_label = 'Amplitude (a.u.)'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Visualize the Amplitude Data\n============================\nNote that we are not hard-coding / writing any tick labels / axis labels by hand.\nAll the necessary information was present in the H5 file\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "px.viz.be_viz_utils.jupyter_visualize_be_spectrograms(h5_main)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "1. Singular Value Decomposition (SVD)\n=====================================\n\nSVD is an eigenvector decomposition that is defined statistically, and therefore typically produces\nnon-physical eigenvectors. Consequently, the interpretation of eigenvectors and abundance maps from\nSVD requires care and caution in interpretation. Nontheless, it is a good method for quickly\nvisualizing the major trends in the dataset since the resultant eigenvectors are sorted in descending\norder of variance or importance. Furthermore, SVD is also very well suited for data cleaning through\nthe reconstruction of the dataset using only the first N (most significant) components.\n\nSVD results in three matrices:\n* V - Eigenvectors sorted by variance in descending order\n* U - corresponding bundance maps\n* S - Variance or importance of each of these components\n\nAdvantage of pycroscopy:\n------------------------\nNotice that we are working with a complex valued dataset. Passing the complex values as is to SVD would result in\ncomplex valued eigenvectors / endmembers as well as abundance maps. Complex valued abundance maps are not physical.\nThus, one would need to restructure the data such that it is real-valued only.\n\nOne solution is to stack the real value followed by the magnitude of the imaginary component before passing to SVD.\nAfter SVD, the real-valued eigenvectors would need to be treated as the concatenation of the real and imaginary\ncomponents. So, the eigenvectors would need to be restructured to get back the complex valued eigenvectors.\n\n**Pycroscopy handles all these data transformations (both for the source dataset and the eigenvectors)\nautomatically.**  In general, pycroscopy handles compund / complex valued datasets everywhere possible\n\nFurthermore, while it is not discussed in this example, pycroscopy also writes back the results from SVD back to\nthe same source h5 file including all relevant links to the source dataset and other ancillary datasets\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "h5_svd_group = px.doSVD(h5_main, num_comps=256)\n\nh5_u = h5_svd_group['U']\nh5_v = h5_svd_group['V']\nh5_s = h5_svd_group['S']\n\n# Since the two spatial dimensions (x, y) have been collapsed to one, we need to reshape the abundance maps:\nabun_maps = np.reshape(h5_u[:,:25], (num_rows, num_cols, -1))\n\n# Visualize the variance / statistical importance of each component:\npx.plot_utils.plotScree(h5_s, title='Note the exponential drop of variance with number of components')\n\n# Visualize the eigenvectors:\nfirst_evecs = h5_v[:9, :]\n\npx.plot_utils.plot_loops(freq_vec, np.abs(first_evecs), x_label=x_label, y_label=y_label, plots_on_side=3,\n                         subtitles='Component', title='SVD Eigenvectors (Amplitude)', evenly_spaced=False)\npx.plot_utils.plot_loops(freq_vec, np.angle(first_evecs), x_label=x_label, y_label='Phase (rad)', plots_on_side=3,\n                         subtitles='Component', title='SVD Eigenvectors (Phase)', evenly_spaced=False)\n\n# Visualize the abundance maps:\npx.plot_utils.plot_map_stack(abun_maps, num_comps=9, heading='SVD Abundance Maps',\n                             color_bar_mode='single', cmap='inferno')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "2. KMeans Clustering\n====================\n\nKMeans clustering is a quick and easy method to determine the types of spectral responses present in the\ndata. It is not a decomposition method, but a basic clustering method. The user inputs the number of\nclusters (sets) to partition the data into. The algorithm proceeds to find the optimal labeling\n(ie., assignment of each spectra as belonging to the k<sup>th</sup> set) such that the within-cluster\nsum of squares is minimized.\n\nSet the number of clusters below\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "num_clusters = 4\n\nestimators = px.Cluster(h5_main, 'KMeans', n_clusters=num_clusters)\nh5_kmeans_grp = estimators.do_cluster(h5_main)\nh5_kmeans_labels = h5_kmeans_grp['Labels']\nh5_kmeans_mean_resp = h5_kmeans_grp['Mean_Response']\n\npx.plot_utils.plot_cluster_h5_group(h5_kmeans_grp)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "3. Non-negative Matrix Factorization (NMF)\n===========================================\n\nNMF, or non-negative matrix factorization, is a method that is useful towards unmixing of spectral\ndata. It only works on data with positive real values. It operates by approximate determination of\nfactors (matrices) W and H, given a matrix V, as shown below\n\n![](https://upload.wikimedia.org/wikipedia/commons/f/f9/NMF.png)\n\n\nUnlike SVD and k-Means that can be applied to complex-valued datasets, NMF only works on non-negative datasets.\nFor illustrative purposes, we will only take the amplitude component of the spectral data\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "num_comps = 4\n\n# get the non-negative portion of the dataset\ndata_mat = np.abs(h5_main)\n\nmodel = NMF(n_components=num_comps, init='random', random_state=0)\nmodel.fit(data_mat)\n\nfig, axis = plt.subplots(figsize=(5.5, 5))\npx.plot_utils.plot_line_family(axis, freq_vec, model.components_, label_prefix='NMF Component #')\naxis.set_xlabel(x_label, fontsize=12)\naxis.set_ylabel(y_label, fontsize=12)\naxis.set_title('NMF Components', fontsize=14)\naxis.legend(bbox_to_anchor=[1.0, 1.0], fontsize=12)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "4. NFINDR\n=========\n\nNFINDR is a geometric decomposition technique that can aid in determination of constitent spectra in data.\nThe basic idea is as follows. Assume that at any point *x*, the spectra measured *A(w,x)* is a\nlinear superposition of *k* 'pure' spectra, i.e.\n\n*A(w,x)* = c\\ :sub:`0`\\ (x)a\\ :sub:`0` + c\\ :sub:`1`\\ (x)a\\ :sub:`1` + ... + c\\ :sub:`k`\\ (x)a\\ :sub:`k`\n\nIn this case, our task consists of first determining the pure spectra {a\\ :sub:`0`\\ ,...,a\\ :sub:`k`\\ },\nand then determining the coefficients {c\\ :sub:`0`\\ ,...,c\\ :sub:`k`\\ }. NFINDR determines the 'pure'\nspectra by first projecting the data into a low-dimensional sub-space (typically using PCA), and then\ntaking the convex hull of the points in this space. Then, points are picked at random along the convex\nhull and the volume of the simplex that the points form is determined. If (k+1) pure spectra are needed,\nthe data is reduced to (k) dimensions for this purpose. The points that maximize the volume of the\nsimples are taken as the most representative pure spectra available in the dataset. One way to think of\nthis is that any spectra that lie within the given volume can be represented as a superposition of these\nconstituent spectra; thus maximizing this volume allows the purest spectra to be determined.\n\nThe second task is to determine the coefficients. This is done usign the fully constrained least squares\noptimization, and involves the sum-to-one constraint, to allow quantitative comparisons to be made.\nMore information can be found in the paper below:\n\n`Winter, Michael E. \"N-FINDR: An algorithm for fast autonomous spectral end-member determination in\nhyperspectral data.\" SPIE's International Symposium on Optical Science, Engineering, and Instrumentation.\nInternational Society for Optics and Photonics, 1999.\n<http://proceedings.spiedigitallibrary.org/proceeding.aspx?articleid=994814>`_)\n\nYet again, we will only work with the non-negative portion of the data (Amplitude)\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "num_comps = 4\n\n# get the amplitude component of the dataset\ndata_mat = np.abs(h5_main)\n\nnfindr_results = eea.nfindr.NFINDR(data_mat, num_comps) #Find endmembers\nend_members = nfindr_results[0]\n\nfig, axis = plt.subplots(figsize=(5.5, 5))\npx.plot_utils.plot_line_family(axis, freq_vec, end_members, label_prefix='NFINDR endmember #')\naxis.set_title('NFINDR Endmembers', fontsize=14)\naxis.set_xlabel(x_label, fontsize=12)\naxis.set_ylabel(y_label, fontsize=12)\naxis.legend(bbox_to_anchor=[1.0,1.0], fontsize=12)\n\n# fully constrained least squares model:\nfcls = amp.FCLS()\n# Find abundances:\namap = fcls.map(data_mat[np.newaxis, :, :], end_members)\n\n# Reshaping amap\namap = np.reshape(np.squeeze(amap), (num_rows, num_cols, -1))\n\npx.plot_utils.plot_map_stack(amap, heading='NFINDR Abundance maps', cmap=plt.cm.inferno,\n                             color_bar_mode='single');"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Close and delete the h5_file\nh5_file.close()\nos.remove(data_file_path)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}